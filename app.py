import streamlit as st
import google.generativeai as genai
import requests
from bs4 import BeautifulSoup
import re
import datetime
import concurrent.futures
import os
import markdown
from docx import Document
from docx.shared import Pt, RGBColor
from io import BytesIO

# ==========================================
# 0. ã€ç½‘ç»œé…ç½®ã€‘
# ==========================================
if "OS" in os.environ:
    os.environ["http_proxy"] = "http://127.0.0.1:7897"
    os.environ["https_proxy"] = "http://127.0.0.1:7897"

# ==========================================
# 1. é…ç½®åŒºåŸŸ
# ==========================================
try:
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
except FileNotFoundError:
    st.error("âŒ æœªæ‰¾åˆ°å¯†é’¥é…ç½®ï¼è¯·ç¡®ä¿æœ¬åœ°æœ‰ .streamlit/secrets.toml æˆ–äº‘ç«¯å·²é…ç½® Secretsã€‚")
    st.stop()

genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-flash-latest')

# ==========================================
# 2. æ ¸å¿ƒåŠŸèƒ½
# ==========================================
def extract_urls(text):
    url_pattern = r'(https?://[^\s]+)'
    return re.findall(url_pattern, text)

def scrape_one_url(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    try:
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            paragraphs = soup.find_all('p')
            text = "\n".join([p.get_text() for p in paragraphs])
            if len(text) < 50: text = soup.get_text()
            return url, text[:2500] 
        return url, f"[ç½‘é¡µé”™è¯¯: {response.status_code}]"
    except Exception as e:
        return url, f"[æŠ“å–å‡ºé”™: {str(e)}]"

# ğŸŒŸ V1.2 å‡çº§ï¼šPrompt å¼ºåˆ¶åˆ†æ®µ + è§†è§‰éš”ç¦»
def ai_generate_daily_brief(raw_input, scraped_text_block, lang_mode):
    
    # åŸºç¡€ç»“æ„ï¼šè¦æ±‚ AI ä¸¥æ ¼åˆ†è¡Œ
    base_prompt = f"""
    ä½ æ˜¯ä¸€ä½ Chilquinta èƒ½æºå…¬å¸çš„æƒ…æŠ¥ä¸“å®¶ã€‚
    è¯·æ ¹æ®æä¾›çš„ã€åŸå§‹åˆ†ç±»ã€‘å’Œã€æŠ“å–çš„æ­£æ–‡ã€‘ï¼Œå†™ä¸€ä»½æ’ç‰ˆç²¾ç¾çš„æ—¥æŠ¥ã€‚
    æ—¶é—´ï¼š{datetime.date.today()}
    
    ã€æ’ç‰ˆä¸¥æ ¼è¦æ±‚ã€‘ï¼š
    æ¯ä¸€æ¡æ–°é—»å¿…é¡»ä¸¥æ ¼éµå®ˆä»¥ä¸‹ Markdown ç»“æ„ï¼ˆæ³¨æ„ç©ºè¡Œï¼‰ï¼š
    
    ### ğŸŠ [æ ‡é¢˜]
    
    [æ­£æ–‡æ®µè½1]
    
    [æ­£æ–‡æ®µè½2 (å¦‚æœæ˜¯åŒè¯­æ¨¡å¼)]
    
    **ğŸ”— Source:** [URL]
    
    ---
    """

    if lang_mode == "ä¸­æ–‡ (ä¿ç•™è¥¿è¯­æœ¯è¯­)":
        lang_instruction = """
        ã€è¯­è¨€è¦æ±‚ã€‘ï¼š
        1. æ ‡é¢˜ï¼šä¸­æ–‡ã€‚
        2. æ­£æ–‡ï¼šä¸­æ–‡æ‘˜è¦ã€‚
        3. **æœ¯è¯­ä¿ç•™**ï¼šæœºæ„åã€æ³•è§„ã€é¡¹ç›®ååå¿…é¡»ä¿ç•™è¥¿è¯­åŸæ–‡ï¼Œå¦‚ï¼šå›½å®¶èƒ½æºå§”å‘˜ä¼š (CNE)ã€‚
        """
    elif lang_mode == "çº¯è¥¿è¯­ (EspaÃ±ol)":
        lang_instruction = """
        ã€è¯­è¨€è¦æ±‚ã€‘ï¼š
        1. æ ‡é¢˜ï¼šEspaÃ±ol.
        2. æ­£æ–‡ï¼šResumen en EspaÃ±ol (Formal Business Tone).
        """
    else: # ä¸­æ–‡ + è¥¿è¯­ (å¼ºè¡Œåˆ†å¼€)
        lang_instruction = """
        ã€è¯­è¨€è¦æ±‚ - åŒè¯­å¯¹ç…§æ¨¡å¼ã€‘ï¼š
        è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼Œä¸è¦æŠŠä¸­è¥¿æ–‡æ··åœ¨ä¸€æ®µé‡Œï¼š
        
        **ğŸ‡¨ğŸ‡³ ä¸­æ–‡æ‘˜è¦ï¼š**
        [è¿™é‡Œå†™ä¸­æ–‡æ‘˜è¦...]
        
        **ğŸ‡ªğŸ‡¸ EspaÃ±ol:**
        [AquÃ­ el resumen en espaÃ±ol...]
        """

    full_prompt = base_prompt + lang_instruction
    
    try:
        full_content = f"ã€åŸå§‹æ¶ˆæ¯æ¡†æ¶ã€‘:\n{raw_input}\n\nã€æŠ“å–çš„è¯¦ç»†æ­£æ–‡ã€‘:\n{scraped_text_block}"
        response = model.generate_content(full_prompt + "\n\n" + full_content)
        return response.text
    except Exception as e:
        return f"AI æ€è€ƒå‡ºé”™: {str(e)}"

# ğŸŒŸ V1.2 å‡çº§ï¼šCSS å­—ä½“å±‚çº§ä¼˜åŒ–
def convert_to_html_file(markdown_text):
    html_body = markdown.markdown(markdown_text)
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <style>
            /* --- å…¨å±€å­—ä½“è®¾ç½® --- */
            body {{ 
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif; 
                line-height: 1.6; /* è¡Œé«˜é€‚ä¸­ */
                color: #333; 
                background-color: #f4f7f6; 
                max-width: 800px; 
                margin: 0 auto; 
                padding: 20px;
            }}
            .container {{ 
                background-color: #ffffff; 
                padding: 40px; 
                border-radius: 12px; 
                box-shadow: 0 4px 15px rgba(0,0,0,0.05); 
            }}
            
            /* --- 1. ä¸€çº§å¤§æ ‡é¢˜ (åˆ†ç±») --- */
            h2 {{ 
                color: #2c3e50; 
                border-bottom: 2px solid #3498db; 
                padding-bottom: 10px; 
                margin-top: 40px; 
                margin-bottom: 25px;
                font-size: 1.5em; /* çº¦ 24px */
                font-weight: 700;
            }}

            /* --- 2. äºŒçº§å°æ ‡é¢˜ (æ–°é—»æ ‡é¢˜) --- */
            h3 {{ 
                color: #d35400; /* æ©™è‰² */
                margin-top: 30px; 
                margin-bottom: 15px; 
                font-size: 1.2em; /* çº¦ 19pxï¼Œæ¯”æ­£æ–‡å¤§ï¼Œæ¯”åˆ†ç±»å° */
                font-weight: 600;
            }}

            /* --- 3. æ­£æ–‡ (Body Text) - ä½ çš„æ ¸å¿ƒç—›ç‚¹ --- */
            p {{ 
                margin-bottom: 15px; 
                font-size: 15px; /* ğŸ‘ˆ è°ƒå°äº†ï¼æ­£å¸¸çš„é˜…è¯»å­—å· */
                color: #444; /* ç¨å¾®æ·¡ä¸€ç‚¹çš„é»‘ï¼ŒæŠ¤çœ¼ */
                text-align: justify; /* ä¸¤ç«¯å¯¹é½ï¼Œçœ‹èµ·æ¥æ•´é½ */
            }}
            
            /* é’ˆå¯¹åŒè¯­æ ‡ç­¾çš„åŠ ç²—éƒ¨åˆ† */
            strong {{
                color: #2c3e50;
                font-weight: 600;
            }}

            /* --- é“¾æ¥æ ·å¼ (ç‹¬ç«‹æˆè¡Œ) --- */
            /* å¦‚æœ Prompt ç”Ÿæˆäº†åˆ—è¡¨å½¢å¼ */
            ul {{ 
                background-color: #f8f9fa; 
                padding: 10px 15px 10px 35px; 
                border-radius: 6px; 
                border-left: 4px solid #3498db; 
                margin-bottom: 25px; /* å¢åŠ ä¸‹é—´è·ï¼Œä¸ä¸‹ä¸€æ¡æ–°é—»éš”å¼€ */
            }}
            li {{ 
                margin-bottom: 5px; 
                font-size: 13px; /* ğŸ‘ˆ é“¾æ¥å­—ä½“æ›´å°ï¼Œä¸æŠ¢æˆ */
                color: #666; 
                word-break: break-all; 
            }}
            a {{ color: #007bff; text-decoration: none; }}

            .footer {{ margin-top: 40px; text-align: center; font-size: 12px; color: #aaa; }}
            
            /* æ‰‹æœºé€‚é… */
            @media only screen and (max-width: 600px) {{
                body {{ padding: 10px; }}
                .container {{ padding: 20px; }}
                h2 {{ font-size: 1.3em; }}
                h3 {{ font-size: 1.1em; }}
                p {{ font-size: 15px; }} /* æ‰‹æœºä¸Šä¿æŒæ¸…æ™° */
            }}
        </style>
    </head>
    <body>
        <div class="container">{html_body}<div class="footer">âš¡ Generated by Chilquinta AI Assistant â€¢ {datetime.date.today()}</div></div>
    </body>
    </html>
    """
    return html_content

# Word ç”Ÿæˆ (é€»è¾‘å¾®è°ƒï¼Œé€‚é…æ–°çš„ Prompt æ ¼å¼)
def generate_word_file(markdown_text):
    doc = Document()
    doc.add_heading(f'Chilquinta Daily News - {datetime.date.today()}', 0)

    lines = markdown_text.split('\n')
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        if line.startswith('### '):
            clean_line = line.replace('### ', '').replace('ğŸŠ', '').strip()
            heading = doc.add_heading(clean_line, level=2)
            run = heading.runs[0]
            run.font.color.rgb = RGBColor(211, 84, 0)
            
        elif line.startswith('* ') or line.startswith('- '): # åˆ—è¡¨
            clean_line = re.sub(r'^[*-]\s+', '', line)
            clean_line = re.sub(r'\[(.*?)\]\(.*?\)', r'\1', clean_line) 
            doc.add_paragraph(clean_line, style='List Bullet')
            
        elif "Source:" in line or "ğŸ”—" in line:
            p = doc.add_paragraph()
            run = p.add_run(line)
            run.font.size = Pt(9) # Wordé‡Œé“¾æ¥ä¹Ÿå¼„å°ç‚¹
            run.font.color.rgb = RGBColor(100, 100, 100)
            
        elif line.startswith('---'):
            doc.add_paragraph('_' * 20)
            
        else: # æ­£æ–‡
            clean_line = line.replace('**', '')
            p = doc.add_paragraph(clean_line)
            # å¯ä»¥åœ¨è¿™é‡Œè®¾ç½® Word æ­£æ–‡å­—ä½“å¤§å°ï¼Œé»˜è®¤é€šå¸¸æ˜¯ 11pt æˆ– 12ptï¼Œæ¯”è¾ƒåˆé€‚
            
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

# ==========================================
# 3. ç•Œé¢æ„å»º
# ==========================================
st.set_page_config(page_title="Chilquinta News v1.2", page_icon="âš¡", layout="wide")
st.title("âš¡ Chilquinta æ¯æ—¥æ–°é—» (v1.2)")
st.caption("æ’ç‰ˆä¼˜åŒ–ç‰ˆ â€¢ å­—ä½“å±‚çº§æ¸…æ™° â€¢ ç‹¬ç«‹åˆ†è¡Œ")

raw_text = st.text_area("è¯·ç²˜è´´ç¾¤æ¶ˆæ¯:", height=150)

lang_option = st.radio(
    "è¯·é€‰æ‹©ç”Ÿæˆè¯­è¨€:",
    ("ä¸­æ–‡ (ä¿ç•™è¥¿è¯­æœ¯è¯­)", "çº¯è¥¿è¯­ (EspaÃ±ol)", "ä¸­æ–‡ & è¥¿è¯­å¯¹ç…§"),
    horizontal=True
)

if st.button("ğŸš€ å¼€å§‹ç”Ÿæˆæ—¥æŠ¥", type="primary"):
    if not raw_text or "http" not in raw_text:
        st.warning("è¯·ç²˜è´´åŒ…å«é“¾æ¥çš„å†…å®¹ï¼")
    else:
        urls = extract_urls(raw_text)
        status = st.status(f"å‘ç° {len(urls)} æ¡é“¾æ¥ï¼Œæ­£åœ¨å¹¶å‘æŠ“å–...", expanded=True)
        scraped_data_str = ""
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            future_to_url = {executor.submit(scrape_one_url, url): url for url in urls}
            for future in concurrent.futures.as_completed(future_to_url):
                url = future_to_url[future]
                try:
                    _, content = future.result()
                    scraped_data_str += f"\n--- é“¾æ¥ {url} çš„æ­£æ–‡ ---\n{content}\n"
                    status.write(f"âœ… å·²æŠ“å–: {url[:40]}...")
                except:
                    status.write(f"âŒ å¤±è´¥: {url[:40]}")
        
        status.write(f"ğŸ§  AI æ­£åœ¨ç”¨ã€{lang_option}ã€‘æ¨¡å¼æ’°å†™æŠ¥å‘Š...")
        
        report_md = ai_generate_daily_brief(raw_text, scraped_data_str, lang_option)
        report_html = convert_to_html_file(report_md)
        word_file = generate_word_file(report_md)
        
        status.update(label="âœ… å®Œæˆï¼", state="complete", expanded=False)
        st.markdown("---")
        
        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ç½‘é¡µç‰ˆ (.html)",
                data=report_html,
                file_name=f"Chilquinta_News_{datetime.date.today()}.html",
                mime="text/html"
            )
        with col2:
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ Word ç‰ˆ (.docx)",
                data=word_file,
                file_name=f"Chilquinta_News_{datetime.date.today()}.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
            
        st.markdown(report_md)