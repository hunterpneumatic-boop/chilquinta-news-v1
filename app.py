import streamlit as st
import google.generativeai as genai
import requests
from bs4 import BeautifulSoup
import re
import datetime
import concurrent.futures
import os
import markdown

# ==========================================
# 0. ã€ç½‘ç»œé…ç½®ã€‘(æ™ºèƒ½åˆ‡æ¢ - ä¿®å¤ç‰ˆ)
# ==========================================
# è¿™é‡Œæˆ‘ä»¬ç”¨ try-except æ¥â€œè¯•æ¢â€ç¯å¢ƒ
# å¦‚æœåœ¨äº‘ç«¯ï¼Œst.secrets èƒ½è¯»å–ï¼Œè¿™å°±ä¸ä¼šæŠ¥é”™
# å¦‚æœåœ¨æœ¬åœ°ï¼Œst.secrets ä¼šæŠ¥é”™ï¼Œæˆ‘ä»¬å°±æ•è·é”™è¯¯å¹¶å¼€å¯ä»£ç†
try:
    # è¯•å›¾è¯»å–äº‘ç«¯é…ç½®ï¼ˆä¸åšä»»ä½•å®é™…æ“ä½œï¼Œåªæ˜¯ä¸ºäº†æµ‹è¯•ï¼‰
    test_key = st.secrets["GEMINI_API_KEY"]
except:
    # æŠ¥é”™äº†è¯´æ˜åœ¨æœ¬åœ° -> å¼€å¯æ¢¯å­ï¼
    os.environ["http_proxy"] = "http://127.0.0.1:7897"
    os.environ["https_proxy"] = "http://127.0.0.1:7897"

# ==========================================
# 1. é…ç½®åŒºåŸŸ
# ==========================================
# å°è¯•ä» Streamlit Secrets (äº‘ç«¯) è·å– Key
try:
    # ğŸ‘‡ã€åƒä¸‡åˆ«åŠ¨è¿™ä¸€è¡Œï¼ã€‘äº‘ç«¯ç”¨
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
except:
    # ğŸ‘‡ã€åœ¨è¿™é‡Œå¡«å…¥ä½ çš„çœŸå® Keyï¼ã€‘æœ¬åœ°ç”¨
    GEMINI_API_KEY = "AIzaSyBp2t6IgQUk_sD4Uy92JGW_j6D12eclY3A"

genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-flash-latest')

# ==========================================
# 2. æ ¸å¿ƒåŠŸèƒ½ (ä¿æŒä¸å˜)
# ==========================================

def extract_urls(text):
    url_pattern = r'(https?://[^\s]+)'
    return re.findall(url_pattern, text)

def scrape_one_url(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    try:
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            paragraphs = soup.find_all('p')
            text = "\n".join([p.get_text() for p in paragraphs])
            if len(text) < 50: text = soup.get_text()
            return url, text[:2500] 
        return url, f"[ç½‘é¡µé”™è¯¯: {response.status_code}]"
    except Exception as e:
        return url, f"[æŠ“å–å‡ºé”™: {str(e)}]"

def ai_generate_daily_brief(raw_input, scraped_text_block):
    prompt = f"""
    ä½ æ˜¯ä¸€ä½ Chilquinta èƒ½æºå…¬å¸çš„æƒ…æŠ¥ä¸“å®¶ã€‚
    è¯·æ ¹æ®æä¾›çš„ã€åŸå§‹åˆ†ç±»ã€‘å’Œã€æŠ“å–çš„æ­£æ–‡ã€‘ï¼Œå†™ä¸€ä»½æ’ç‰ˆç²¾ç¾çš„ä¸­æ–‡æ—¥æŠ¥ã€‚

    ã€æ’ç‰ˆä¸¥æ ¼è¦æ±‚ã€‘ï¼š
    è¯·å¯¹æ¯ä¸€æ¡æ–°é—»ä½¿ç”¨ä»¥ä¸‹ Markdown æ ¼å¼ï¼š

    ### ğŸŠ [è¿™é‡Œå†™ä¸­æ–‡æ ‡é¢˜] (è¿™é‡Œä¿ç•™è¥¿è¯­åŸæ–‡æœ¯è¯­)
    
    [è¿™é‡Œå†™è¯¦ç»†çš„æ–°é—»æ‘˜è¦ï¼ŒåŒ…å«å…·ä½“æ•°æ®ã€‚æ³¨æ„ï¼šæ‘˜è¦å†™å®Œåå¿…é¡»æ¢è¡Œ]

    **ğŸ”— æ¥æºé“¾æ¥ï¼š**
    * [é“¾æ¥1]

    ---

    ã€å†…å®¹è¦æ±‚ã€‘ï¼š
    1. **ç»“æ„å¤åˆ»**ï¼šä¿ç•™åŸå§‹æ¶ˆæ¯ä¸­çš„åˆ†ç±»ã€‚
    2. **æ·±åº¦æ‘˜è¦**ï¼šæ¦‚æ‹¬æ ¸å¿ƒäº‹å®ã€‚
    3. **æœ¯è¯­ä¿ç•™**ï¼šæœºæ„åã€æ³•è§„ã€é¡¹ç›®ååœ¨ä¸­æ–‡åä¿ç•™è¥¿è¯­åŸæ–‡ã€‚
    
    ã€æ—¶é—´ã€‘ï¼š{datetime.date.today()}
    """
    
    try:
        full_content = f"ã€åŸå§‹æ¶ˆæ¯æ¡†æ¶ã€‘:\n{raw_input}\n\nã€æŠ“å–çš„è¯¦ç»†æ­£æ–‡ã€‘:\n{scraped_text_block}"
        response = model.generate_content(prompt + "\n\n" + full_content)
        return response.text
    except Exception as e:
        return f"AI æ€è€ƒå‡ºé”™: {str(e)}"

#CSS æ ·å¼
def convert_to_html_file(markdown_text):
    html_body = markdown.markdown(markdown_text)
    
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0"> <style>
            /* --- åŸºç¡€æ ·å¼ (ç”µè„‘ç«¯) --- */
            body {{ 
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif; 
                line-height: 1.8; 
                color: #333; 
                max-width: 800px; 
                margin: 0 auto; 
                padding: 20px;
                background-color: #f4f7f6; 
            }}
            .container {{ 
                background-color: #ffffff; 
                padding: 40px; 
                border-radius: 12px; 
                box-shadow: 0 4px 15px rgba(0,0,0,0.05); 
            }}
            h2 {{ color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; margin-top: 30px; }}
            h3 {{ color: #d35400; margin-top: 25px; margin-bottom: 10px; font-size: 1.15em; font-weight: 600; }}
            p {{ margin-bottom: 15px; text-align: justify; }}
            
            /* é“¾æ¥æ ·å¼ä¼˜åŒ– */
            ul {{ 
                background-color: #f8f9fa; 
                padding: 15px 15px 15px 35px; 
                border-radius: 8px; 
                border-left: 5px solid #3498db;
                margin-bottom: 20px;
            }}
            li {{ margin-bottom: 8px; font-size: 0.95em; word-break: break-all; color: #555; }}
            a {{ color: #007bff; text-decoration: none; font-weight: 500; }}
            a:hover {{ text-decoration: underline; }}
            
            .footer {{ margin-top: 40px; text-align: center; font-size: 0.8em; color: #aaa; }}

            /* --- ğŸ“± æ‰‹æœºç«¯ä¸“å±ä¼˜åŒ– (Media Query) --- */
            @media only screen and (max-width: 600px) {{
                body {{
                    padding: 10px; /* æ‰‹æœºä¸Šå‡å°‘å¤–è¾¹è· */
                }}
                .container {{
                    padding: 20px; /* æ‰‹æœºä¸Šå‡å°‘å†…è¾¹è·ï¼Œè®©å­—æ˜¾ç¤ºæ›´å¤š */
                }}
                h2 {{
                    font-size: 1.4em; /* æ ‡é¢˜ç¨å¾®è°ƒå°ä¸€ç‚¹ç‚¹ä»¥å…æ¢è¡Œå¤ªä¸‘ */
                }}
                h3 {{
                    font-size: 1.1em;
                }}
            }}
        </style>
    </head>
    <body>
        <div class="container">
            {html_body}
            <div class="footer">
                âš¡ Generated by Chilquinta AI Assistant â€¢ {datetime.date.today()}
            </div>
        </div>
    </body>
    </html>
    """
    return html_content

# ==========================================
# 3. ç•Œé¢æ„å»º
# ==========================================
st.set_page_config(page_title="Chilquinta News v1.0", page_icon="âš¡", layout="wide")

st.title("âš¡ Chilquinta æ¯æ—¥æ–°é—» (v1.0)")
st.caption("ç²˜è´´ç¾¤æ¶ˆæ¯ -> ç”Ÿæˆç²¾ç¾ HTML æ—¥æŠ¥")

raw_text = st.text_area("è¯·ç²˜è´´ç¾¤æ¶ˆæ¯:", height=200)

if st.button("ğŸš€ å¼€å§‹ç”Ÿæˆæ—¥æŠ¥", type="primary"):
    if not raw_text or "http" not in raw_text:
        st.warning("è¯·ç²˜è´´åŒ…å«é“¾æ¥çš„å†…å®¹ï¼")
    else:
        urls = extract_urls(raw_text)
        status = st.status(f"å‘ç° {len(urls)} æ¡é“¾æ¥ï¼Œæ­£åœ¨å¹¶å‘æŠ“å–...", expanded=True)
        
        scraped_data_str = ""
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            future_to_url = {executor.submit(scrape_one_url, url): url for url in urls}
            for future in concurrent.futures.as_completed(future_to_url):
                url = future_to_url[future]
                try:
                    _, content = future.result()
                    scraped_data_str += f"\n--- é“¾æ¥ {url} çš„æ­£æ–‡ ---\n{content}\n"
                    status.write(f"âœ… å·²æŠ“å–: {url[:40]}...")
                except:
                    status.write(f"âŒ å¤±è´¥: {url[:40]}")

        status.write("ğŸ§  AI æ­£åœ¨æ’°å†™æŠ¥å‘Š...")
        report_md = ai_generate_daily_brief(raw_text, scraped_data_str)
        report_html = convert_to_html_file(report_md)
        
        status.update(label="âœ… å®Œæˆï¼", state="complete", expanded=False)
        
        st.markdown("---")
        st.markdown(report_md) 
        
        date_str = datetime.datetime.now().strftime("%Y-%m-%d")
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½ç²¾ç¾æ’ç‰ˆæ—¥æŠ¥ (.html)",
            data=report_html,
            file_name=f"Chilquinta_Report_{date_str}.html",
            mime="text/html"
        )