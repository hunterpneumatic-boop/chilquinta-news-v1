import streamlit as st
import google.generativeai as genai
import requests
from bs4 import BeautifulSoup
import re
import datetime
import concurrent.futures
import os
import markdown
from docx import Document # ğŸ‘ˆ V1.1 æ–°å¢ï¼šç”¨äºå¤„ç† Word
from docx.shared import Pt, RGBColor # ğŸ‘ˆ V1.1 æ–°å¢ï¼šç”¨äºè°ƒæ•´ Word å­—ä½“é¢œè‰²
from io import BytesIO # ğŸ‘ˆ V1.1 æ–°å¢ï¼šç”¨äºåœ¨å†…å­˜ä¸­ç”Ÿæˆæ–‡ä»¶

# ==========================================
# 0. ã€ç½‘ç»œé…ç½®ã€‘
# ==========================================
if "OS" in os.environ:
    os.environ["http_proxy"] = "http://127.0.0.1:7897"
    os.environ["https_proxy"] = "http://127.0.0.1:7897"

# ==========================================
# 1. é…ç½®åŒºåŸŸ
# ==========================================
try:
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
except FileNotFoundError:
    st.error("âŒ æœªæ‰¾åˆ°å¯†é’¥é…ç½®ï¼è¯·ç¡®ä¿æœ¬åœ°æœ‰ .streamlit/secrets.toml æˆ–äº‘ç«¯å·²é…ç½® Secretsã€‚")
    st.stop()

genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-flash-latest')

# ==========================================
# 2. æ ¸å¿ƒåŠŸèƒ½
# ==========================================
def extract_urls(text):
    url_pattern = r'(https?://[^\s]+)'
    return re.findall(url_pattern, text)

def scrape_one_url(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    try:
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            paragraphs = soup.find_all('p')
            text = "\n".join([p.get_text() for p in paragraphs])
            if len(text) < 50: text = soup.get_text()
            return url, text[:2500] 
        return url, f"[ç½‘é¡µé”™è¯¯: {response.status_code}]"
    except Exception as e:
        return url, f"[æŠ“å–å‡ºé”™: {str(e)}]"

# ğŸŒŸ V1.1 å‡çº§ï¼šæ”¯æŒå¤šè¯­è¨€ Prompt
def ai_generate_daily_brief(raw_input, scraped_text_block, lang_mode):
    
    # åŸºç¡€è¦æ±‚
    base_prompt = f"""
    ä½ æ˜¯ä¸€ä½ Chilquinta èƒ½æºå…¬å¸çš„æƒ…æŠ¥ä¸“å®¶ã€‚
    è¯·æ ¹æ®æä¾›çš„ã€åŸå§‹åˆ†ç±»ã€‘å’Œã€æŠ“å–çš„æ­£æ–‡ã€‘ï¼Œå†™ä¸€ä»½æ’ç‰ˆç²¾ç¾çš„æ—¥æŠ¥ã€‚
    æ—¶é—´ï¼š{datetime.date.today()}
    
    ã€æ’ç‰ˆä¸¥æ ¼è¦æ±‚ã€‘ï¼š
    è¯·å¯¹æ¯ä¸€æ¡æ–°é—»ä½¿ç”¨ä»¥ä¸‹ Markdown æ ¼å¼ï¼š
    ### ğŸŠ [æ ‡é¢˜]
    [æ­£æ–‡å†…å®¹]
    **ğŸ”— Source:** [URL]
    ---
    """

    # æ ¹æ®é€‰æ‹©çš„è¯­è¨€æ¨¡å¼ï¼Œè°ƒæ•´æŒ‡ä»¤
    if lang_mode == "ä¸­æ–‡ (ä¿ç•™è¥¿è¯­æœ¯è¯­)":
        lang_instruction = """
        ã€è¯­è¨€è¦æ±‚ã€‘ï¼š
        1. ä½¿ç”¨**ä¸­æ–‡**æ’°å†™æ‘˜è¦ã€‚
        2. **æœ¯è¯­ä¿ç•™**ï¼šæ‰€æœ‰æœºæ„åã€æ³•è§„ã€é¡¹ç›®åã€äººåï¼Œå¿…é¡»åœ¨ä¸­æ–‡åä¿ç•™è¥¿è¯­åŸæ–‡ï¼Œä¾‹å¦‚ï¼šå›½å®¶èƒ½æºå§”å‘˜ä¼š (CNE)ã€‚
        3. æ ‡é¢˜ä½¿ç”¨ä¸­æ–‡ã€‚
        """
    elif lang_mode == "çº¯è¥¿è¯­ (EspaÃ±ol)":
        lang_instruction = """
        ã€è¯­è¨€è¦æ±‚ã€‘ï¼š
        1. ä½¿ç”¨**ä¸“ä¸šè¥¿ç­ç‰™è¯­ (EspaÃ±ol)** æ’°å†™æ‘˜è¦ã€‚
        2. é£æ ¼è¦æ­£å¼ã€å•†åŠ¡ (Formal Business Tone)ã€‚
        3. æ ‡é¢˜ä½¿ç”¨è¥¿è¯­ã€‚
        """
    else: # ä¸­æ–‡ + è¥¿è¯­
        lang_instruction = """
        ã€è¯­è¨€è¦æ±‚ã€‘ï¼š
        1. **åŒè¯­å¯¹ç…§æ¨¡å¼**ï¼šå¯¹äºæ¯ä¸€æ¡æ–°é—»ï¼Œå…ˆå†™ä¸€æ®µä¸­æ–‡æ‘˜è¦ï¼Œç´§æ¥ç€æ¢è¡Œï¼Œå†™ä¸€æ®µè¥¿ç­ç‰™è¯­æ‘˜è¦ã€‚
        2. æ ¼å¼å¦‚ä¸‹ï¼š
           [ä¸­æ–‡æ‘˜è¦å†…å®¹...]
           
           (EspaÃ±ol): [Resumen en espaÃ±ol...]
        3. æ ‡é¢˜ä½¿ç”¨ï¼šä¸­æ–‡æ ‡é¢˜ / TÃ­tulo en EspaÃ±ol
        """

    full_prompt = base_prompt + lang_instruction
    
    try:
        full_content = f"ã€åŸå§‹æ¶ˆæ¯æ¡†æ¶ã€‘:\n{raw_input}\n\nã€æŠ“å–çš„è¯¦ç»†æ­£æ–‡ã€‘:\n{scraped_text_block}"
        response = model.generate_content(full_prompt + "\n\n" + full_content)
        return response.text
    except Exception as e:
        return f"AI æ€è€ƒå‡ºé”™: {str(e)}"

# ç”Ÿæˆ HTML (ä¿æŒä¸å˜ï¼Œç”¨äºé¢„è§ˆå’Œç½‘é¡µä¸‹è½½)
def convert_to_html_file(markdown_text):
    html_body = markdown.markdown(markdown_text)
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <style>
            body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif; line-height: 1.8; color: #333; max-width: 800px; margin: 0 auto; padding: 20px; background-color: #f4f7f6; }}
            .container {{ background-color: #ffffff; padding: 40px; border-radius: 12px; box-shadow: 0 4px 15px rgba(0,0,0,0.05); }}
            h2 {{ color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; margin-top: 30px; }}
            h3 {{ color: #d35400; margin-top: 25px; margin-bottom: 10px; font-size: 1.15em; font-weight: 600; }}
            p {{ margin-bottom: 15px; text-align: justify; }}
            ul {{ background-color: #f8f9fa; padding: 15px 15px 15px 35px; border-radius: 8px; border-left: 5px solid #3498db; margin-bottom: 20px; }}
            li {{ margin-bottom: 8px; font-size: 0.95em; word-break: break-all; color: #555; }}
            a {{ color: #007bff; text-decoration: none; font-weight: 500; }}
            .footer {{ margin-top: 40px; text-align: center; font-size: 0.8em; color: #aaa; }}
            @media only screen and (max-width: 600px) {{
                body {{ padding: 10px; }}
                .container {{ padding: 20px; }}
                h2 {{ font-size: 1.4em; }}
            }}
        </style>
    </head>
    <body>
        <div class="container">{html_body}<div class="footer">âš¡ Generated by Chilquinta AI Assistant â€¢ {datetime.date.today()}</div></div>
    </body>
    </html>
    """
    return html_content

# ğŸŒŸ V1.1 æ–°å¢ï¼šç”Ÿæˆ Word æ–‡æ¡£
def generate_word_file(markdown_text):
    doc = Document()
    doc.add_heading(f'Chilquinta Daily News - {datetime.date.today()}', 0)

    # ç®€å•çš„ Markdown è§£æé€»è¾‘
    lines = markdown_text.split('\n')
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # å¤„ç†æ ‡é¢˜ (###)
        if line.startswith('### '):
            clean_line = line.replace('### ', '').replace('ğŸŠ', '').strip() # å»æ‰ emoji ä»¥å… Word ä¹±ç 
            heading = doc.add_heading(clean_line, level=2)
            run = heading.runs[0]
            run.font.color.rgb = RGBColor(211, 84, 0) # æ©™è‰²
            
        # å¤„ç†åˆ—è¡¨ (*)
        elif line.startswith('* '):
            clean_line = line.replace('* ', '').strip()
            # å»æ‰ Markdown é“¾æ¥æ ¼å¼ [text](url) ä¿ç•™ text
            clean_line = re.sub(r'\[(.*?)\]\(.*?\)', r'\1', clean_line) 
            doc.add_paragraph(clean_line, style='List Bullet')
            
        # å¤„ç†æ¥æºé“¾æ¥
        elif "Source:" in line or "æ¥æºé“¾æ¥" in line:
            doc.add_paragraph(line, style='Intense Quote')
            
        # å¤„ç†åˆ†å‰²çº¿
        elif line.startswith('---'):
            doc.add_paragraph('_' * 50)
            
        # æ™®é€šæ­£æ–‡
        else:
            # å»æ‰ç²—ä½“ç¬¦å·
            clean_line = line.replace('**', '')
            doc.add_paragraph(clean_line)

    # ä¿å­˜åˆ°å†…å­˜æµ
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

# ==========================================
# 3. ç•Œé¢æ„å»º
# ==========================================
st.set_page_config(page_title="Chilquinta News v1.1", page_icon="âš¡", layout="wide")
st.title("âš¡ Chilquinta æ¯æ—¥æ–°é—» (v1.1)")
st.caption("æ”¯æŒå¤šè¯­è¨€åˆ‡æ¢ â€¢ æ”¯æŒ Word ä¸‹è½½")

# è¾“å…¥åŒº
raw_text = st.text_area("è¯·ç²˜è´´ç¾¤æ¶ˆæ¯:", height=150)

# ğŸŒŸ V1.1 æ–°å¢ï¼šè¯­è¨€é€‰æ‹©å™¨
lang_option = st.radio(
    "è¯·é€‰æ‹©ç”Ÿæˆè¯­è¨€:",
    ("ä¸­æ–‡ (ä¿ç•™è¥¿è¯­æœ¯è¯­)", "çº¯è¥¿è¯­ (EspaÃ±ol)", "ä¸­æ–‡ & è¥¿è¯­å¯¹ç…§"),
    horizontal=True
)

if st.button("ğŸš€ å¼€å§‹ç”Ÿæˆæ—¥æŠ¥", type="primary"):
    if not raw_text or "http" not in raw_text:
        st.warning("è¯·ç²˜è´´åŒ…å«é“¾æ¥çš„å†…å®¹ï¼")
    else:
        urls = extract_urls(raw_text)
        status = st.status(f"å‘ç° {len(urls)} æ¡é“¾æ¥ï¼Œæ­£åœ¨å¹¶å‘æŠ“å–...", expanded=True)
        scraped_data_str = ""
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            future_to_url = {executor.submit(scrape_one_url, url): url for url in urls}
            for future in concurrent.futures.as_completed(future_to_url):
                url = future_to_url[future]
                try:
                    _, content = future.result()
                    scraped_data_str += f"\n--- é“¾æ¥ {url} çš„æ­£æ–‡ ---\n{content}\n"
                    status.write(f"âœ… å·²æŠ“å–: {url[:40]}...")
                except:
                    status.write(f"âŒ å¤±è´¥: {url[:40]}")
        
        status.write(f"ğŸ§  AI æ­£åœ¨ç”¨ã€{lang_option}ã€‘æ¨¡å¼æ’°å†™æŠ¥å‘Š...")
        
        # ä¼ é€’è¯­è¨€å‚æ•°
        report_md = ai_generate_daily_brief(raw_text, scraped_data_str, lang_option)
        
        # ç”Ÿæˆæ–‡ä»¶
        report_html = convert_to_html_file(report_md)
        word_file = generate_word_file(report_md) # ç”Ÿæˆ Word
        
        status.update(label="âœ… å®Œæˆï¼", state="complete", expanded=False)
        st.markdown("---")
        
        # ğŸŒŸ V1.1 å‡çº§ï¼šåŒä¸‹è½½æŒ‰é’®
        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ç½‘é¡µç‰ˆ (.html)",
                data=report_html,
                file_name=f"Chilquinta_News_{datetime.date.today()}.html",
                mime="text/html"
            )
        with col2:
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ Word ç‰ˆ (.docx)",
                data=word_file,
                file_name=f"Chilquinta_News_{datetime.date.today()}.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
            
        st.markdown(report_md)